[![omp-5.png](https://i.postimg.cc/90szPbH9/omp-5.png)](https://postimg.cc/V0BYmj6s)
Python script that summarizes PDF documents using a large language model (LLM) returning text files.

**transforming 1000 pages into less than 100**

# Explanation
"Compartiendo resumidor": In this notebook you will be able to make the summary in a drive folder where you have your books, or PDF files. It is a useful prototype to extract many valuable concepts from multiple books

"Compartiendo creador de word" : in this file you can create a .docx file , unifying the rest of the text files generated by summarizing.

## "resumidor" Code description:
This code utilizes Google Colab and the palm library to process and summarize multiple PDF documents related to value investing. Here's a breakdown:

**1. Installation and Setup:**

- The code starts by installing the required library `PyPDF2` for PDF processing using `!pip install PyPDF2`.
- It acknowledges the need for an API key for the palm library and provides a link to obtain one ([https://aistudio.google.com/app/waitlist/97445851](https://aistudio.google.com/app/waitlist/97445851)). A placeholder with dots (...) is used where the actual key should be placed.
- It mentions a helpful YouTube channel, Analytics Vidhya ([https://www.youtube.com/channel/UCH6gDteHtH4hg3o2343iObA](https://www.youtube.com/channel/UCH6gDteHtH4hg3o2343iObA)), as a resource for learning more.

**2. Mounting Google Drive and Defining Directory:**

- It mounts Google Drive using `from google.colab import drive` for accessing the PDF files.
- It defines the directory containing the PDFs (`directory`).

**3. Looping Through PDFs and Extracting Text:**

- It iterates through each PDF file in the defined directory (`pdf_files`).
- It opens the PDF and uses `PdfReader` from `PyPDF2` to extract text from each page.
- The extracted text from all pages of a PDF is stored in a list `text`.

**4. Optional: Compressing Text (Commented Out):**

- The code defines a function `join_elements` to combine consecutive elements in the text list (`new_text`). This could potentially reduce the number of API calls needed for summarization.
- However, this functionality is currently commented out (`# Option to keep x elements per list element`).

**5. Processing Each PDF and Summarizing:**

- It iterates through each PDF's text list (`new_text`).
- For each chunk of text, it constructs a prompt that instructs a large language model (LLM) to summarize the content. 
- The prompt emphasizes clarity, accessibility, and conciseness (under 150 words).
- It utilizes the `palm.generate_text` function to call the LLM and retrieve the summary.
- The code includes error handling to potentially retry the API call if the first attempt fails.
- To avoid exceeding the free API quota (3 calls per minute), it introduces a delay of 19 seconds between calls using `time.sleep(19)`.
- The retrieved summaries are concatenated for each PDF.

**6. Saving Summaries:**

- It creates a new text file with the format `summar_34_{pdf_name}.txt` in the same directory for each PDF.
- It writes the concatenated summaries (all summaries for a particular PDF) to the respective text file.

**Overall, this code effectively utilizes Google Colab, PyPDF2, and the palm library to automate PDF processing and generate summaries using a large language model.**
 
